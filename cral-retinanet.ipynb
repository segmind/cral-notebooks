{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import zipfile\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "from cral.pipeline import ObjectDetectionPipe\n",
    "from cral.models.object_detection import RetinanetConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Chess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_chess_dataset(dataset_path=tempfile.gettempdir()):\n",
    "    zip_url = 'https://public.roboflow.ai/ds/uBYkFHtqpy?key=HZljsh2sXY'\n",
    "    path_to_zip_file = tf.keras.utils.get_file(\n",
    "        'chess_pieces.zip',\n",
    "        zip_url,\n",
    "        cache_dir=dataset_path, \n",
    "        cache_subdir='',\n",
    "        extract=False)\n",
    "    directory_to_extract_to = os.path.join(dataset_path,'chess_pieces')\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory_to_extract_to)\n",
    "\n",
    "    images_dir = os.path.join(dataset_path, 'chess_pieces','train')\n",
    "    annotation_dir = os.path.join(dataset_path, 'chess_pieces','train')\n",
    "\n",
    "    for image in tqdm.tqdm(glob.glob(os.path.join(images_dir, '*.jpg'))):\n",
    "        new_name = image.replace('_jpg.rf.', '')\n",
    "        os.rename(image, new_name)\n",
    "\n",
    "        annotation = image.replace('.jpg', '.xml')\n",
    "        new_name = annotation.replace('_jpg.rf.', '')\n",
    "        os.rename(annotation, new_name)\n",
    "\n",
    "    return images_dir, annotation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://public.roboflow.ai/ds/uBYkFHtqpy?key=HZljsh2sXY\n",
      "8060928/8055750 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202/202 [00:00<00:00, 31012.06it/s]\n"
     ]
    }
   ],
   "source": [
    "images_dir, annotation_dir = download_chess_dataset('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SetUp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/202 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing Training Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 202/202 [00:00<00:00, 763.16it/s]\n",
      " 10%|██████                                                       | 16/161 [00:00<00:01, 100.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating train Tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 161/161 [00:00<00:00, 549.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 1397.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating test Tfrecords\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pipe = ObjectDetectionPipe()\n",
    "\n",
    "pipe.add_data(\n",
    "    train_images_dir=images_dir,\n",
    "    train_anno_dir=annotation_dir,\n",
    "    annotation_format='pascal_voc',\n",
    "    split=0.2)\n",
    "\n",
    "pipe.lock_data()\n",
    "\n",
    "pipe.set_algo(feature_extractor='resnet50', config=RetinanetConfig())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/12/17 08:59:15 INFO segmind.store.tracking.rest_store: Artifact upload HTTP status code: 204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/40 [==============================] - 30s 722ms/step - loss: 3.1791 - regression_loss: 2.1880 - classification_loss: 0.9911 - val_loss: 1.9959 - val_regression_loss: 1.5388 - val_classification_loss: 0.4571\n",
      "Epoch 2/10\n",
      "41/40 [==============================] - 28s 692ms/step - loss: 1.4852 - regression_loss: 1.1122 - classification_loss: 0.3730 - val_loss: 1.1949 - val_regression_loss: 0.9010 - val_classification_loss: 0.2939\n",
      "Epoch 3/10\n",
      "41/40 [==============================] - 29s 699ms/step - loss: 1.2042 - regression_loss: 0.9374 - classification_loss: 0.2669 - val_loss: 1.3440 - val_regression_loss: 1.0974 - val_classification_loss: 0.2466\n",
      "Epoch 4/10\n",
      "41/40 [==============================] - 28s 691ms/step - loss: 1.0187 - regression_loss: 0.8089 - classification_loss: 0.2098 - val_loss: 0.8803 - val_regression_loss: 0.7127 - val_classification_loss: 0.1676\n",
      "Epoch 5/10\n",
      "41/40 [==============================] - 28s 683ms/step - loss: 0.8771 - regression_loss: 0.7344 - classification_loss: 0.1427 - val_loss: 0.8091 - val_regression_loss: 0.6850 - val_classification_loss: 0.1241\n",
      "Epoch 6/10\n",
      "41/40 [==============================] - 28s 683ms/step - loss: 0.7246 - regression_loss: 0.6250 - classification_loss: 0.0996 - val_loss: 0.6433 - val_regression_loss: 0.5574 - val_classification_loss: 0.0859\n",
      "Epoch 7/10\n",
      "41/40 [==============================] - 28s 683ms/step - loss: 0.6708 - regression_loss: 0.5900 - classification_loss: 0.0807 - val_loss: 0.6675 - val_regression_loss: 0.5948 - val_classification_loss: 0.0727\n",
      "Epoch 8/10\n",
      "41/40 [==============================] - 28s 682ms/step - loss: 0.6264 - regression_loss: 0.5535 - classification_loss: 0.0729 - val_loss: 0.6957 - val_regression_loss: 0.6164 - val_classification_loss: 0.0793\n",
      "Epoch 9/10\n",
      "41/40 [==============================] - 28s 682ms/step - loss: 0.5847 - regression_loss: 0.5248 - classification_loss: 0.0599 - val_loss: 0.6006 - val_regression_loss: 0.5341 - val_classification_loss: 0.0665\n",
      "Epoch 10/10\n",
      "41/40 [==============================] - ETA: 0s - loss: 0.5348 - regression_loss: 0.4864 - classification_loss: 0.0484\n",
      "Epoch 00010: saving model to /tmp/retinanet_test_10.h5\n",
      "Uploading checkpoint /tmp/retinanet_test_10.h5 ...\n",
      "41/40 [==============================] - 30s 728ms/step - loss: 0.5348 - regression_loss: 0.4864 - classification_loss: 0.0484 - val_loss: 0.5720 - val_regression_loss: 0.5139 - val_classification_loss: 0.0581\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tmp/test_retinanet_final/assets\n",
      "Saved the final Model to :\n",
      " /tmp/test_retinanet_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/12/17 09:05:59 INFO segmind.store.tracking.rest_store: Artifact upload HTTP status code: 204\n"
     ]
    }
   ],
   "source": [
    "from segmind.keras import CheckpointCallback, KerasCallback\n",
    "\n",
    "keras_cb = KerasCallback()\n",
    "ckpt_cb = CheckpointCallback(\n",
    "            snapshot_interval=10,\n",
    "            snapshot_path='/tmp',\n",
    "            checkpoint_prefix='retinanet_test')\n",
    "pipe.train(\n",
    "    num_epochs=10,\n",
    "    snapshot_prefix='test_retinanet',\n",
    "    snapshot_path='/tmp',\n",
    "    snapshot_every_n=10,\n",
    "    batch_size=4,\n",
    "    #steps_per_epoch=100,\n",
    "    callbacks=[keras_cb, ckpt_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cral.models.object_detection import annotate_image\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting ...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file= '/tmp/test_retinanet_final'\n",
    "prediction_func= pipe.prediction_model(checkpoint_file= checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and annotate Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path= 'chess_pieces/test/5a35ba2ec3e0d0b2b12b1758a8ac29aa_jpg.rf.280f9940defacbb5d840aef65a9257e5.jpg'\n",
    "\n",
    "# make prediction\n",
    "bboxes, scores, labels= prediction_func(img_path)\n",
    "\n",
    "# draw predictions on image and save\n",
    "image_array= np.array(Image.open(img_path))\n",
    "drawn_image= annotate_image(image_array, bboxes, scores, labels, threshold=0.5)\n",
    "drawn_image.save('image_retinanet.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
